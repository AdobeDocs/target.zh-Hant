---
keywords: 隨機森林；決策樹；ap;Automated Personalization
description: 了解Adobe [!DNL Target] 在Automated Personalization(AP)和自動鎖定目標活動中使用隨機森林演算法。
title: 如何 [!DNL Target] 使用隨機森林演算法嗎？
feature: Automated Personalization
exl-id: 07a89525-4071-4434-ac96-c59a4f4422ad
source-git-commit: 293b2869957c2781be8272cfd0cc9f82d8e4f0f0
workflow-type: tm+mt
source-wordcount: '1427'
ht-degree: 94%

---

# ![PREMIUM](/help/main/assets/premium.png) 隨機森林演算法

Target 用於自動個人化和自動鎖定目標的主要個人化演算法為隨機森林 (Random Forest)。隨機森林之類的整體方法會使用多個學習演算法，相較於任何建構式學習演算法可獲得更好的預測性效能。自動個人化中的隨機森林演算法為一種分類或迴歸方法，其運作方式是在訓練時建構許多決策。

在思考統計學時，您可能會想到使用單一迴歸模型來預測結果。最新的資料科學研究指出，「整體方法」可從相同資料集建立多個模型，然後進行智慧式合併，因此產生的結果比根據單一模型來預測更好。

「隨機森林」演算法是自動個人化和自動鎖定目標活動中，主要採用的基本個人化演算法。隨機森林將數百個決策樹合併在一起，可達成比獨自單個樹更好的預測。

## 什麼是決策樹？ {#section_7F5865D8064447F4856FED426243FDAC}

決策樹的目標是將可供系統學習的所有資料分解，然後將資料分組，而就目標量度而言，每一組內的造訪皆儘可能彼此相似。不過，就目標量度而言 (例如，轉換率)，各組之間的造訪截然不同。決策樹會檢查訓練集內的不同變數，以決定如何以 MECE (Mutually-Exclusive-Collectively-Exhaustive - 彼此獨立，互無遺漏) 方法，將資料分割成這些群組，以儘可能達成此目標。

簡單舉例，假設我們只有兩個輸入變數。

* 性別 (兩個可能值: 男或女)
* 郵遞區號 (在我們的小型資料集內有五個可能值: 11111、22222、33333、44444 或 55555)

如果目標量度是轉換，則樹狀會先從兩個變數中，決定何者可說明造訪資料的轉換率出現最大變數。

假設郵遞區號最可預測。此變數會形成樹狀結構的第一個「分支」。接著，決策樹會決定如何分割造訪資料，例如每個分割內的記錄轉換率儘可能相似，而分割之間的轉換率儘可能不同。在我們的範例中，假設 11111、22222、33333 是第一個分割，44444 和 55555 是第二個分割。

此動作會產生決策樹的第一層:

![decision_tree_1映像](assets/decsion_tree_1.png)

決策樹會問:「哪一個是最可預測的變數?」在我們的範例中，只有兩個變數，所以答案顯然是性別。現在，樹狀結構將開始完成類似的練習，以分割&#x200B;*每個分支內*&#x200B;的資料。首先，以 11111、22222 和 33333 分支為例。在這些郵遞區號中，如果男和女的轉換率不同，則會有兩個分葉 (男和女)，而此分支也就完成。在另一個分支中 (44444 和 55555)，假設男和女的轉換方式之間沒有統計差異。在此情況下，第一個分支就成為最終分割。

我們的範例會產生下列樹狀結構:

![decision_tree_2映像](assets/decsion_tree_2.png)

## 隨機森林如何使用決策樹？ {#section_536C105EF9F540C096D60450CAC6F627}

決策樹雖然是強大的統計工具，但有一些缺點。最嚴重的情況是可能會「過度配適」資料，以致於個別樹狀結構難以預測並未用來建立原始樹狀結構的未來資料。在統計學習中，此難題稱為[偏誤及變數之權衡](https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff)隨機森林有助於克服此過度配適難題。站在最高的角度來看，隨機森林是一群在相同資料集上以稍微不同的方式建立的決策樹，經過共同「表決」而產生比個別狀結構更好的模型。樹狀結構的建立方式是隨機選取造訪記錄子集並抽出放回 (稱為自助重抽總合法)，以及隨機選取屬性子集，而使森林包含略為不同的決策樹。此方法會對隨機森林中建立的樹狀結構造成輕微變化。加入此控制的變數有助於改善演算法的預測準確度。

## Target的個人化演算法如何使用隨機森林？ {#section_32FB53CAD8DF40FB9C0F1217FBDBB691}

**如何建立模型**

下圖彙總如何建立自動鎖定目標或自動個人化活動的模型:

![random_forest_flow影像](assets/random_forest_flow.png)

1. Target 在隨機提供體驗/選件時收集訪客的資料
1. Target 在取得非常大量的資料後，即會展開特徵工程
1. Target 為每個體驗/選件建立隨機森林模型
1. Target 檢查模型是否符合臨界品質分數
1. Target 將模型推到生產環境來個人化未來流量

Target 會使用它自動收集的資料，以及您提供的自訂資料，以建立其個人化演算法。這些模型會預測最佳體驗或選件來顯示給訪客。一般而言，每個體驗 (若為自動鎖定目標活動) 或每個選件 (若為自動個人化活動) 各建立一個模型。然後，Target 會選擇顯示預測成功量度 (例如轉換率) 最高的體驗或選件。這些模型必須在隨機提供的造訪上經過訓練，才能用來預測。因此，當活動最初開始時，即使對於個人化群組中的訪客，也會隨機顯示不同的體驗或選件，直到個人化演算法就緒為止。

每個模型必須經過驗證，確保可以準確預測訪客行為，才能用於活動中。模型是根據其 AUC (曲線下面積) 來驗證。因為需要驗證，模型開始提供個人化體驗的確切時間取決於資料的細節。在實務上及流量規劃用途上，每個模型通常要超過最低轉換次數才有效。

當體驗或選件的模型變得有效時，體驗/選件名稱左邊的時鐘圖示會變成綠色核取方塊。當至少兩個體驗/選件出現有效的模型時，部分造訪會開始變得個人化。

** 特徵轉換 **

資料會進入個人化演算法之前會經過特徵轉換，可視為預備好訓練記錄中收集的資料，以供個人化模型使用。

特徵轉換視屬性類型而定。主要有兩種屬性 (資料科學家有時會說成「特徵」):

* **類別:**&#x200B;類別特徵無法計數，但可分類成不同群組。這種特徵包括國家/地區、性別或郵遞區號。
* **數值:**&#x200B;數值特徵可測量或計數，例如年齡、收入等。

對於類別特徵，存在一組所有可能的特徵，概度轉換用來降低資料大小。對於數值特徵，重新換算確保特徵可全面比較。

**使用多臂吃角子老虎機來平衡學習與個人化**

當 Target 建立個人化模型來個人化您的流量後，針對未來進入活動的訪客，您需要做出明確的取捨: 根據目前的模型將所有流量個人化? 或對新訪客隨機提供隨選件來繼續從中學習? 您需要確保個人化演算法一定會學習到訪客的最新趨勢，同時又將多數的流量個人化。

Target 採用多臂吃角子老虎機協助您達成此目標。多臂吃角子老虎機可確保模型一律會「消費」一小部分的流量以繼續在整個活動學習期間中學習，並且防止過度利用先前學習的趨勢。

在資料科學領域中，多臂吃角子老虎機 (MAB) 問題向來是探索與利用兩難的典型範例，其中假設一批單臂吃角子老虎機，且各自的報酬機率未知。主要概念是開發一套策略，只玩成功機率最高的臂，使獲得的總報酬最大化。建立線上模型後，系統中會使用多臂吃角子老虎機在線上計分。這有助於探索期間在線上學習。目前的多臂演算法是 epsilon (ε) 貪婪演算法。在此演算法中，根據機率 1- ε 來選擇最佳的臂。此外，根據機率 ε 會隨機選擇任何其他臂。
